[
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 500,
      "learning_rate": 0.01,
      "max_depth": 4,
      "reg_alpha": 0.1,
      "reg_lambda": 2.0,
      "subsample": 0.8,
      "colsample_bytree": 0.8,
      "model_type": "xgboost",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5585042219541616,
      "auc": 0.5677194330899393,
      "sharpe": 0.09594123591125649,
      "sharpe_train": 4.0068546769726145,
      "elapsed_seconds": 1.1568574905395508,
      "n_features": 13
    },
    "note": "Conservative XGB: low LR + high n_estimators + regularization to prevent overfit on vol/RSI features",
    "interpretation": "Val Sharpe=0.096, Train Sharpe=4.007 \u2014 below threshold"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 300,
      "learning_rate": 0.05,
      "max_depth": 4,
      "reg_alpha": 0.5,
      "reg_lambda": 1.0,
      "subsample": 0.9,
      "colsample_bytree": 0.7,
      "model_type": "xgboost",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5392038600723763,
      "auc": 0.5534942761648558,
      "sharpe": -0.18553493251899944,
      "sharpe_train": 6.4932323031638175,
      "elapsed_seconds": 0.44954848289489746,
      "n_features": 13
    },
    "note": "Moderate XGB: balanced LR/depth with feature col subsampling for diversity on all 20 features",
    "interpretation": "Val Sharpe=-0.186, Train Sharpe=6.493 \u2014 below threshold"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 200,
      "learning_rate": 0.05,
      "max_depth": 3,
      "reg_alpha": 0.0,
      "reg_lambda": 1.0,
      "min_child_weight": 5,
      "model_type": "xgboost",
      "feature_set": "top10",
      "n_features": 10
    },
    "metrics": {
      "accuracy": 0.5512665862484921,
      "auc": 0.5570199955746544,
      "sharpe": -0.03828505239372633,
      "sharpe_train": 3.5653769808292854,
      "elapsed_seconds": 0.21460962295532227,
      "n_features": 10
    },
    "note": "Shallow XGB on top-10 only: avoids noise from lower-ranked features, emphasizes volume+RSI signal",
    "interpretation": "Val Sharpe=-0.038, Train Sharpe=3.565 \u2014 below threshold"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 500,
      "learning_rate": 0.02,
      "max_depth": 6,
      "reg_alpha": 1.0,
      "reg_lambda": 5.0,
      "subsample": 0.7,
      "colsample_bytree": 0.6,
      "model_type": "xgboost",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5609167671893848,
      "auc": 0.5715974332995609,
      "sharpe": 0.5807741924167744,
      "sharpe_train": 7.685361843342309,
      "elapsed_seconds": 1.1888556480407715,
      "n_features": 13
    },
    "note": "Deep XGB with heavy L1+L2 reg: tests if complex interactions can be learned without overfitting",
    "interpretation": "Val Sharpe=0.581, Train Sharpe=7.685 \u2014 OVERFIT (train 2\u00d7 val)"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 1000,
      "learning_rate": 0.01,
      "max_depth": 3,
      "reg_alpha": 0.0,
      "reg_lambda": 1.0,
      "subsample": 0.8,
      "colsample_bytree": 0.8,
      "model_type": "xgboost",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5705669481302774,
      "auc": 0.5658444840396417,
      "sharpe": 0.3628430245256319,
      "sharpe_train": 4.016246995031772,
      "elapsed_seconds": 0.9669513702392578,
      "n_features": 13
    },
    "note": "Very long training XGB (1000 trees, low LR): ensemble effect with gradient boosting on all features",
    "interpretation": "Val Sharpe=0.363, Train Sharpe=4.016 \u2014 OVERFIT (train 2\u00d7 val)"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 300,
      "learning_rate": 0.1,
      "max_depth": 3,
      "reg_alpha": 2.0,
      "reg_lambda": 2.0,
      "subsample": 0.6,
      "colsample_bytree": 0.5,
      "model_type": "xgboost",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5307599517490953,
      "auc": 0.5653262527803979,
      "sharpe": 0.04975521087013334,
      "sharpe_train": 4.915536725508105,
      "elapsed_seconds": 0.3542470932006836,
      "n_features": 13
    },
    "note": "High LR, aggressive dropout-style subsampling, stochastic gradient boosting for noisy financial data",
    "interpretation": "Val Sharpe=0.050, Train Sharpe=4.916 \u2014 below threshold"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 500,
      "learning_rate": 0.03,
      "max_depth": 5,
      "reg_alpha": 0.5,
      "reg_lambda": 3.0,
      "min_child_weight": 10,
      "model_type": "xgboost",
      "feature_set": "top10",
      "n_features": 10
    },
    "metrics": {
      "accuracy": 0.5404101326899879,
      "auc": 0.5462972667668192,
      "sharpe": 0.07770426349016185,
      "sharpe_train": 6.1490189190356475,
      "elapsed_seconds": 0.8265724182128906,
      "n_features": 10
    },
    "note": "High min_child_weight (10): requires large leaf samples, reduces noise-fitting on sparse features",
    "interpretation": "Val Sharpe=0.078, Train Sharpe=6.149 \u2014 below threshold"
  },
  {
    "config": {
      "tree_method": "hist",
      "device": "cuda",
      "random_state": 42,
      "eval_metric": "logloss",
      "n_estimators": 200,
      "learning_rate": 0.2,
      "max_depth": 4,
      "reg_alpha": 0.0,
      "reg_lambda": 0.5,
      "subsample": 1.0,
      "colsample_bytree": 1.0,
      "model_type": "xgboost",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5078407720144753,
      "auc": 0.5194365836332087,
      "sharpe": -0.29925221997086976,
      "sharpe_train": 8.957567116654806,
      "elapsed_seconds": 0.28318262100219727,
      "n_features": 13
    },
    "note": "Fast learner (lr=0.2, no reg): tests if raw gradient signal without regularization extracts more alpha",
    "interpretation": "Val Sharpe=-0.299, Train Sharpe=8.958 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 500,
      "learning_rate": 0.01,
      "num_leaves": 31,
      "min_child_samples": 20,
      "feature_fraction": 0.8,
      "bagging_fraction": 0.8,
      "bagging_freq": 5,
      "reg_alpha": 0.1,
      "reg_lambda": 1.0,
      "model_type": "lightgbm",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5416164053075995,
      "auc": 0.5623624358033749,
      "sharpe": 0.11492453599967212,
      "sharpe_train": 6.9302796884068245,
      "elapsed_seconds": 10.85880184173584,
      "n_features": 13
    },
    "note": "Conservative LGBM: standard 31 leaves, bagging for variance reduction on 15-feature subset",
    "interpretation": "Val Sharpe=0.115, Train Sharpe=6.930 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 300,
      "learning_rate": 0.05,
      "num_leaves": 63,
      "min_child_samples": 30,
      "feature_fraction": 0.7,
      "bagging_fraction": 0.9,
      "bagging_freq": 3,
      "reg_alpha": 0.5,
      "reg_lambda": 2.0,
      "model_type": "lightgbm",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5355850422195416,
      "auc": 0.5552818828680898,
      "sharpe": -0.27779255192302454,
      "sharpe_train": 9.625037811298197,
      "elapsed_seconds": 10.875052452087402,
      "n_features": 13
    },
    "note": "64-leaf LGBM (more complex than XGB default): explores richer momentum+vol interactions",
    "interpretation": "Val Sharpe=-0.278, Train Sharpe=9.625 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 1000,
      "learning_rate": 0.01,
      "num_leaves": 15,
      "min_child_samples": 50,
      "feature_fraction": 1.0,
      "reg_alpha": 0.0,
      "reg_lambda": 0.5,
      "model_type": "lightgbm",
      "feature_set": "top10",
      "n_features": 10
    },
    "metrics": {
      "accuracy": 0.5452352231604343,
      "auc": 0.5499481768740756,
      "sharpe": -0.22899913004823833,
      "sharpe_train": 5.4115675727600525,
      "elapsed_seconds": 6.549860715866089,
      "n_features": 10
    },
    "note": "Shallow 15-leaf LGBM on top-10: high min_samples prevents overfitting sparse cryptocurrency signals",
    "interpretation": "Val Sharpe=-0.229, Train Sharpe=5.412 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 300,
      "learning_rate": 0.05,
      "num_leaves": 127,
      "min_child_samples": 15,
      "feature_fraction": 0.6,
      "bagging_fraction": 0.8,
      "bagging_freq": 5,
      "reg_alpha": 1.0,
      "reg_lambda": 5.0,
      "model_type": "lightgbm",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5379975874547648,
      "auc": 0.5628224388312429,
      "sharpe": -0.06293149136685994,
      "sharpe_train": 9.656367645276408,
      "elapsed_seconds": 11.827394008636475,
      "n_features": 13
    },
    "note": "128-leaf deep LGBM + heavy L1+L2: tests if very complex decision boundaries exist in BTC hourly data",
    "interpretation": "Val Sharpe=-0.063, Train Sharpe=9.656 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 500,
      "learning_rate": 0.02,
      "num_leaves": 31,
      "min_child_samples": 100,
      "feature_fraction": 0.9,
      "reg_alpha": 0.3,
      "reg_lambda": 1.0,
      "model_type": "lightgbm",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5404101326899879,
      "auc": 0.5519337595639869,
      "sharpe": 0.17486726786087095,
      "sharpe_train": 6.1475199389031925,
      "elapsed_seconds": 5.103135585784912,
      "n_features": 13
    },
    "note": "Very conservative min_samples=100: rejects noisy splits, focuses on robust large-scale patterns",
    "interpretation": "Val Sharpe=0.175, Train Sharpe=6.148 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 200,
      "learning_rate": 0.1,
      "num_leaves": 31,
      "min_child_samples": 20,
      "feature_fraction": 0.8,
      "bagging_fraction": 0.7,
      "bagging_freq": 10,
      "reg_alpha": 0.0,
      "reg_lambda": 0.0,
      "model_type": "lightgbm",
      "feature_set": "top10",
      "n_features": 10
    },
    "metrics": {
      "accuracy": 0.5162846803377563,
      "auc": 0.5225809081274966,
      "sharpe": -0.6120986684287687,
      "sharpe_train": 9.277267875889553,
      "elapsed_seconds": 2.3995754718780518,
      "n_features": 10
    },
    "note": "No regularization LGBM on top-10: tests pure gradient signal without explicit penalty on compact feature set",
    "interpretation": "Val Sharpe=-0.612, Train Sharpe=9.277 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 500,
      "learning_rate": 0.03,
      "num_leaves": 63,
      "min_child_samples": 40,
      "feature_fraction": 0.7,
      "bagging_fraction": 0.8,
      "bagging_freq": 5,
      "reg_alpha": 0.5,
      "reg_lambda": 2.0,
      "max_depth": 6,
      "model_type": "lightgbm",
      "feature_set": "top15",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5319662243667069,
      "auc": 0.5552469459292644,
      "sharpe": 0.025011644328627194,
      "sharpe_train": 6.810239291908694,
      "elapsed_seconds": 6.429062128067017,
      "n_features": 13
    },
    "note": "Depth-limited LGBM: combined max_depth + num_leaves double-constraint for cleaner tree structure",
    "interpretation": "Val Sharpe=0.025, Train Sharpe=6.810 \u2014 below threshold"
  },
  {
    "config": {
      "device": "gpu",
      "random_state": 42,
      "verbose": -1,
      "n_jobs": -1,
      "n_estimators": 300,
      "learning_rate": 0.05,
      "num_leaves": 31,
      "min_child_samples": 30,
      "feature_fraction": 0.5,
      "bagging_fraction": 0.6,
      "bagging_freq": 3,
      "reg_alpha": 2.0,
      "reg_lambda": 2.0,
      "model_type": "lightgbm",
      "feature_set": "top20",
      "n_features": 13
    },
    "metrics": {
      "accuracy": 0.5476477683956574,
      "auc": 0.5695943821402369,
      "sharpe": 0.17610469799387604,
      "sharpe_train": 7.588952544999208,
      "elapsed_seconds": 5.5053369998931885,
      "n_features": 13
    },
    "note": "Aggressive feature + sample subsampling (50%/60%): stochastic ensemble on full 20 features",
    "interpretation": "Val Sharpe=0.176, Train Sharpe=7.589 \u2014 below threshold"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 500,
      "learning_rate": 0.01,
      "depth": 4,
      "l2_leaf_reg": 3.0,
      "rsm": 0.8,
      "border_count": 64,
      "model_type": "catboost",
      "feature_set": "top15"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "CatBoost with border_count=64 (more bins) + rsm=0.8: finer split thresholds for smooth momentum signals",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 300,
      "learning_rate": 0.05,
      "depth": 5,
      "l2_leaf_reg": 5.0,
      "rsm": 0.7,
      "border_count": 32,
      "model_type": "catboost",
      "feature_set": "top20"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "Higher LR CatBoost with L2=5 + coarser bins (32): tests if heavy regularization prevents RSI/vol overfit",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 1000,
      "learning_rate": 0.01,
      "depth": 3,
      "l2_leaf_reg": 1.0,
      "rsm": 1.0,
      "od_type": "Iter",
      "od_wait": 50,
      "model_type": "catboost",
      "feature_set": "top10",
      "n_features": 10
    },
    "metrics": {
      "accuracy": 0.5548854041013269,
      "auc": 0.5722903492529319,
      "sharpe": 0.27600027361448287,
      "sharpe_train": 2.430577703001338,
      "elapsed_seconds": 34.724754333496094,
      "n_features": 10
    },
    "note": "Long CatBoost with early stopping on top-10: uses all features but stops before overfitting begins",
    "interpretation": "Val Sharpe=0.276, Train Sharpe=2.431 \u2014 OVERFIT (train 2\u00d7 val)"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 200,
      "learning_rate": 0.01,
      "depth": 6,
      "l2_leaf_reg": 10.0,
      "rsm": 0.8,
      "border_count": 128,
      "model_type": "catboost",
      "feature_set": "top15"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "Deep CatBoost (depth=6) with very high L2=10: complex interactions + aggressive shrinkage for stability",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 500,
      "learning_rate": 0.02,
      "depth": 4,
      "l2_leaf_reg": 2.0,
      "rsm": 0.6,
      "bagging_temperature": 0.5,
      "model_type": "catboost",
      "feature_set": "top20"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "CatBoost with Bayesian bagging (temperature=0.5) + high feature drop: diversified ensemble effect",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 300,
      "learning_rate": 0.05,
      "depth": 3,
      "l2_leaf_reg": 1.0,
      "rsm": 0.9,
      "grow_policy": "Lossguide",
      "max_leaves": 31,
      "model_type": "catboost",
      "feature_set": "top15"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "LossGuide growth policy: leaf-wise like LGBM rather than depth-first, may find finer signal boundaries",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 200,
      "learning_rate": 0.03,
      "depth": 4,
      "l2_leaf_reg": 3.0,
      "rsm": 0.8,
      "border_count": 64,
      "model_type": "catboost",
      "feature_set": "top10"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "CatBoost on minimal top-10 set + moderate rsm: focused on purest signals (vol dry-up + RSI divergence)",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  },
  {
    "config": {
      "task_type": "GPU",
      "devices": "0",
      "random_state": 42,
      "verbose": 0,
      "iterations": 500,
      "learning_rate": 0.01,
      "depth": 5,
      "l2_leaf_reg": 5.0,
      "rsm": 0.7,
      "border_count": 64,
      "bagging_temperature": 1.0,
      "model_type": "catboost",
      "feature_set": "top20"
    },
    "metrics": {
      "sharpe": 0.0,
      "accuracy": 0.0,
      "auc": 0.5,
      "elapsed_seconds": 0.0
    },
    "note": "Long conservative CatBoost: full Bayesian bagging + L2=5 + fine bins on all 20 features",
    "interpretation": "ERROR: catboost/private/libs/options/catboost_options.cpp:637: Error: rsm on GPU is supported for pairwise modes only"
  }
]