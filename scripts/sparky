#!/home/akamath/sparky-ai/.venv/bin/python3
"""Sparky AI operator CLI.

Usage:
    sparky status    — Dashboard: step, budget, wandb, GPU, alerts
    sparky logs      — Tail latest session log
    sparky watch     — Auto-refresh status every 30s
    sparky pause     — Pause workflow (graceful, after current session)
    sparky resume    — Resume workflow + start systemd service
    sparky stop      — Stop systemd service immediately
    sparky start     — Start systemd service
    sparky skip <step>  — Skip a step
    sparky retry <step> — Reset a step for retry
    sparky inject "msg" — Inject guidance into next session
    sparky budget    — Detailed budget/cost breakdown
    sparky history   — Step completion timeline
    sparky orch status   — Orchestrator status dashboard
    sparky orch results  — Show top results from wandb
    sparky orch respond "msg" — Respond to a gate request and resume
"""

import argparse
import json
import os
import subprocess
import time
from datetime import datetime, timezone
from pathlib import Path

PROJECT_ROOT = Path("/home/akamath/sparky-ai")
STATE_DIR = PROJECT_ROOT / "workflows" / "state"
LOG_DIR = PROJECT_ROOT / "logs" / "research_sessions"
TELEMETRY_DIR = PROJECT_ROOT / "logs" / "telemetry"
ALERTS_LOG = PROJECT_ROOT / "logs" / "alerts.log"
SERVICE_NAME = "sparky-research"


def _load_state() -> dict | None:
    """Load the most recent workflow state file."""
    if not STATE_DIR.exists():
        return None
    state_files = sorted(STATE_DIR.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    for sf in state_files:
        try:
            with open(sf) as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError):
            continue
    return None


def _save_state(state: dict) -> None:
    """Save workflow state back to disk."""
    name = state.get("workflow_name", "unknown")
    filepath = STATE_DIR / f"{name}.json"
    state["updated_at"] = datetime.now(timezone.utc).isoformat()
    with open(filepath, "w") as f:
        json.dump(state, f, indent=2)


def _get_systemd_status() -> str:
    """Get systemd service status."""
    try:
        result = subprocess.run(
            ["systemctl", "--user", "is-active", SERVICE_NAME],
            capture_output=True,
            text=True,
            timeout=5,
        )
        return result.stdout.strip()
    except Exception:
        return "unknown"


def _get_gpu_stats() -> str:
    """Get GPU utilization and memory."""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total", "--format=csv,noheader,nounits"],
            capture_output=True,
            text=True,
            timeout=5,
        )
        parts = result.stdout.strip().split(", ")
        if len(parts) == 3:
            util, mem_used, mem_total = parts
            return f"{util}% util, {float(mem_used) / 1024:.1f}GB/{float(mem_total) / 1024:.0f}GB"
    except Exception:
        pass
    return "unavailable"


_WANDB_CACHE: list[dict] | None = None


def _get_wandb_runs() -> list[dict]:
    """Fetch all wandb runs via a single GraphQL call (~0.5s vs ~35s with SDK)."""
    global _WANDB_CACHE
    if _WANDB_CACHE is not None:
        return _WANDB_CACHE
    try:
        import requests as _req

        # Read API key from netrc (handles multi-line format)
        api_key = None
        netrc_path = Path.home() / ".netrc"
        if netrc_path.exists():
            tokens = netrc_path.read_text().split()
            for i, tok in enumerate(tokens):
                if tok == "machine" and i + 1 < len(tokens) and tokens[i + 1] == "api.wandb.ai":
                    # Find "password" token after this machine entry
                    for j in range(i + 2, min(i + 8, len(tokens))):
                        if tokens[j] == "password" and j + 1 < len(tokens):
                            api_key = tokens[j + 1]
                            break
                    break
        if not api_key:
            _WANDB_CACHE = []
            return []

        query = """
        query Runs($project: String!, $entity: String!, $order: String, $first: Int) {
          project(name: $project, entityName: $entity) {
            runs(order: $order, first: $first) {
              edges {
                node { tags summaryMetrics }
              }
            }
          }
        }
        """
        resp = _req.post(
            "https://api.wandb.ai/graphql",
            json={
                "query": query,
                "variables": {
                    "project": "sparky-ai",
                    "entity": "datadex_ai",
                    "order": "-created_at",
                    "first": 500,
                },
            },
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=15,
        )
        resp.raise_for_status()
        edges = resp.json()["data"]["project"]["runs"]["edges"]
        runs = []
        for edge in edges:
            node = edge["node"]
            summary = {}
            sm = node.get("summaryMetrics")
            if sm:
                try:
                    summary = json.loads(sm)
                except (json.JSONDecodeError, TypeError):
                    pass
            runs.append({"tags": node.get("tags") or [], "summary": summary})
        _WANDB_CACHE = runs
        return runs
    except Exception:
        _WANDB_CACHE = []
        return []


def _get_wandb_counts(state: dict) -> str:
    """Get wandb run counts by tag."""
    try:
        runs = _get_wandb_runs()
        total = len(runs)
        tags_to_check = ["sweep", "regime", "ensemble", "feature_analysis"]
        counts = {}
        for run in runs:
            run_tags = set(run["tags"])
            for tag in tags_to_check:
                if tag in run_tags:
                    counts[tag] = counts.get(tag, 0) + 1
        parts = ", ".join(f"{k}: {v}" for k, v in counts.items())
        return f"{total} runs ({parts})" if parts else f"{total} runs"
    except Exception as e:
        return f"unavailable ({e})"


def _get_best_sharpe(state: dict) -> str:
    """Get best Sharpe from wandb."""
    try:
        runs = _get_wandb_runs()
        best = None
        for run in runs:
            s = run["summary"]
            val = s.get("sharpe") or s.get("sharpe_ratio") or s.get("best_sharpe")
            if val is not None:
                if best is None or val > best:
                    best = val
        if best is not None:
            return f"Sharpe {best:.3f}"
        return "N/A"
    except Exception:
        return "N/A"


def _get_latest_log_line() -> str:
    """Get the last meaningful line from latest.log."""
    latest = LOG_DIR / "latest.log"
    if not latest.exists():
        return "(no log)"
    try:
        # Read last few lines and find last non-empty one
        result = subprocess.run(
            ["tail", "-5", str(latest)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        lines = [l.strip() for l in result.stdout.strip().split("\n") if l.strip()]
        if lines:
            line = lines[-1]
            return line[:80] + "..." if len(line) > 80 else line
    except Exception:
        pass
    return "(no log)"


def _get_recent_alerts() -> str:
    """Get recent alerts."""
    if not ALERTS_LOG.exists():
        return "none"
    try:
        result = subprocess.run(
            ["tail", "-3", str(ALERTS_LOG)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        lines = [l.strip() for l in result.stdout.strip().split("\n") if l.strip()]
        if lines:
            return "; ".join(lines[-2:])
    except Exception:
        pass
    return "none"


def cmd_status(_args):
    """Print workflow status dashboard."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return

    svc_status = _get_systemd_status()
    wf_name = state.get("workflow_name", "unknown")
    steps = state.get("steps", {})
    budget = state.get("budget", {})
    current_idx = state.get("current_step_index", 0)
    total_steps = len(steps)

    # Find current step info
    step_names = list(steps.keys())
    if current_idx < total_steps:
        current_step = step_names[current_idx]
        step_info = steps[current_step]
        attempts = step_info.get("attempts", 0)
        max_retries = 3  # default
        step_status = step_info.get("status", "pending")

        # Estimate elapsed time for current step
        last_attempt = step_info.get("last_attempt_at", "")
        elapsed_str = ""
        if last_attempt and step_status == "running":
            try:
                start = datetime.fromisoformat(last_attempt)
                elapsed = (datetime.now(timezone.utc) - start).total_seconds() / 60
                elapsed_str = f", {elapsed:.0f} min elapsed"
            except Exception:
                pass

        step_line = (
            f"Step {current_idx + 1}/{total_steps}: {current_step} (attempt {attempts}/{max_retries}{elapsed_str})"
        )
    else:
        step_line = f"All {total_steps} steps completed"

    hours_used = budget.get("hours_used", 0)
    max_hours = budget.get("max_hours", 24)
    pct = (hours_used / max_hours * 100) if max_hours > 0 else 0

    gpu_stats = _get_gpu_stats()
    wandb_counts = _get_wandb_counts(state)
    best = _get_best_sharpe(state)
    last_log = _get_latest_log_line()
    alerts = _get_recent_alerts()

    print(f"Sparky AI \u2014 {wf_name} ({svc_status})")
    print(f"{step_line}")
    print(f"Budget: {hours_used:.1f} / {max_hours:.1f} hours ({pct:.0f}%)")
    print(f"Wandb: {wandb_counts}")
    print(f"Best: {best}")
    print(f"GPU: {gpu_stats}")
    print(f'Last log: "{last_log}"')
    print(f"Alerts: {alerts}")


def cmd_logs(_args):
    """Tail latest session log."""
    latest = LOG_DIR / "latest.log"
    if not latest.exists():
        print("No log file found.")
        return
    os.execvp("tail", ["tail", "-f", str(latest)])


def cmd_watch(_args):
    """Auto-refresh status every 30s."""
    try:
        while True:
            os.system("clear")
            print(f"[{datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}] sparky watch (Ctrl+C to stop)\n")
            cmd_status(_args)
            print()
            # Show last 10 lines of log
            latest = LOG_DIR / "latest.log"
            if latest.exists():
                result = subprocess.run(
                    ["tail", "-10", str(latest)],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )
                print("--- Latest log ---")
                print(result.stdout.strip())
            time.sleep(30)
    except KeyboardInterrupt:
        print("\nStopped.")


def cmd_pause(_args):
    """Pause workflow."""
    STATE_DIR.mkdir(parents=True, exist_ok=True)
    (STATE_DIR / "PAUSE").touch()
    print("Workflow paused. Current session will finish, then workflow stops.")
    print("Resume with: sparky resume")


def cmd_resume(_args):
    """Resume workflow."""
    pause_file = STATE_DIR / "PAUSE"
    if pause_file.exists():
        pause_file.unlink()
        print("PAUSE file removed.")
    subprocess.run(["systemctl", "--user", "start", SERVICE_NAME])
    print(f"Started {SERVICE_NAME}.")


def cmd_stop(_args):
    """Stop systemd service."""
    subprocess.run(["systemctl", "--user", "stop", SERVICE_NAME])
    print(f"Stopped {SERVICE_NAME}.")


def cmd_start(_args):
    """Start systemd service."""
    subprocess.run(["systemctl", "--user", "start", SERVICE_NAME])
    print(f"Started {SERVICE_NAME}.")


def cmd_skip(args):
    """Skip a workflow step."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return
    step_name = args.step
    steps = state.get("steps", {})
    if step_name not in steps:
        print(f"Step '{step_name}' not found. Available: {', '.join(steps.keys())}")
        return
    steps[step_name]["status"] = "skipped"
    # Advance current_step_index if needed
    step_names = list(steps.keys())
    current_idx = state.get("current_step_index", 0)
    if current_idx < len(step_names) and step_names[current_idx] == step_name:
        state["current_step_index"] = current_idx + 1
    _save_state(state)
    print(f"Step '{step_name}' marked as skipped.")


def cmd_retry(args):
    """Reset a step for retry."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return
    step_name = args.step
    steps = state.get("steps", {})
    if step_name not in steps:
        print(f"Step '{step_name}' not found. Available: {', '.join(steps.keys())}")
        return
    steps[step_name]["attempts"] = 0
    steps[step_name]["status"] = "pending"
    _save_state(state)
    print(f"Step '{step_name}' reset for retry (attempts=0, status=pending).")


def cmd_inject(args):
    """Inject guidance into next session."""
    STATE_DIR.mkdir(parents=True, exist_ok=True)
    inject_file = STATE_DIR / "inject.md"
    inject_file.write_text(args.message)
    print(f"Guidance written to {inject_file}")
    print("Will be injected into the next Claude session prompt, then deleted.")


def cmd_budget(_args):
    """Show detailed budget and cost breakdown."""
    state = _load_state()
    budget = state.get("budget", {}) if state else {}
    hours_used = budget.get("hours_used", 0)
    max_hours = budget.get("max_hours", 24)
    cost = budget.get("estimated_cost_usd", 0)
    runs = budget.get("runs_completed", 0)

    print(f"Budget: {hours_used:.2f} / {max_hours:.1f} hours ({hours_used / max_hours * 100:.1f}%)")
    print(f"Estimated cost: ${cost:.2f}")
    print(f"Total runs: {runs}")

    # Load telemetry files for per-step breakdown
    if TELEMETRY_DIR.exists():
        by_step: dict[str, dict] = {}
        for tf in sorted(TELEMETRY_DIR.glob("*.json")):
            try:
                with open(tf) as f:
                    t = json.load(f)
                step = t.get("step", "unknown")
                if step not in by_step:
                    by_step[step] = {"runs": 0, "hours": 0.0, "cost": 0.0}
                by_step[step]["runs"] += 1
                by_step[step]["hours"] += t.get("duration_minutes", 0) / 60.0
                by_step[step]["cost"] += t.get("estimated_cost_usd", 0)
            except (json.JSONDecodeError, OSError):
                continue

        if by_step:
            print("\nPer-step breakdown:")
            print(f"  {'Step':<30} {'Runs':>5} {'Hours':>8} {'Cost':>8}")
            print(f"  {'-' * 30} {'-' * 5} {'-' * 8} {'-' * 8}")
            for step, info in by_step.items():
                print(f"  {step:<30} {info['runs']:>5} {info['hours']:>8.2f} ${info['cost']:>7.2f}")


def cmd_history(_args):
    """Show step completion timeline."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return

    steps = state.get("steps", {})
    print(f"Workflow: {state.get('workflow_name', 'unknown')}")
    print(f"Created: {state.get('created_at', 'unknown')}")
    print()
    print(f"  {'Step':<30} {'Status':<12} {'Attempts':>8} {'Completed':>24}")
    print(f"  {'-' * 30} {'-' * 12} {'-' * 8} {'-' * 24}")
    for name, info in steps.items():
        completed = info.get("completed_at", "") or "-"
        print(f"  {name:<30} {info.get('status', '?'):<12} {info.get('attempts', 0):>8} {completed:>24}")


def _load_orch_state() -> dict | None:
    """Load the most recent orchestrator state file. Falls back to wandb reconstruction."""
    if STATE_DIR.exists():
        state_files = sorted(STATE_DIR.glob("orchestrator_*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
        for sf in state_files:
            try:
                with open(sf) as f:
                    return json.load(f)
            except (json.JSONDecodeError, OSError):
                continue

    # No state file — try to reconstruct from wandb
    return _reconstruct_orch_state_from_wandb()


def _reconstruct_orch_state_from_wandb() -> dict | None:
    """Reconstruct orchestrator state from wandb runs (read-only, does not save)."""
    try:
        # Find the active directive to get tags
        directives_dir = PROJECT_ROOT / "directives"
        active_link = directives_dir / "active.yaml"
        if not active_link.exists():
            return None

        import yaml

        with open(active_link) as f:
            directive_data = yaml.safe_load(f)

        name = directive_data.get("name", "")
        tags = directive_data.get("wandb_tags", [])
        if not name:
            return None

        from sparky.workflow.orchestrator import OrchestratorState

        state = OrchestratorState.reconstruct_from_wandb(name, tags)
        if state is None:
            return None

        # Read-only: return dict for display without saving to disk.
        # Budget/cost data is not available in wandb, so this is a partial view.
        return state.to_dict()
    except Exception:
        return None


def cmd_orch_status(_args):
    """Print orchestrator status dashboard."""
    state = _load_orch_state()
    if not state:
        print("No orchestrator state found.")
        return

    name = state.get("name", "unknown")
    status = state.get("status", "unknown")
    sessions = state.get("session_count", 0)
    best = state.get("best_result", {})
    stall = state.get("stall_counter", 0)
    crash = state.get("crash_counter", 0)
    cost = state.get("total_cost_usd", 0)
    hours = state.get("total_hours", 0)
    gate_msg = state.get("gate_message")

    best_sharpe = best.get("sharpe", "N/A")
    best_dsr = best.get("dsr", "N/A")
    if isinstance(best_sharpe, float):
        best_sharpe = f"{best_sharpe:.3f}"
    if isinstance(best_dsr, float):
        best_dsr = f"{best_dsr:.3f}"

    print(f"Orchestrator: {name} ({status})")
    print(f"Sessions: {sessions}")
    print(f"Best: Sharpe={best_sharpe}, DSR={best_dsr}")
    print(f"Budget: {hours:.1f}h, ${cost:.2f}")
    print(f"Stall counter: {stall}")
    print(f"Crash counter: {crash}")
    if gate_msg:
        print(f"Gate message: {gate_msg}")


def cmd_orch_results(_args):
    """Show top results from wandb for the orchestrator directive."""
    state = _load_orch_state()
    if not state:
        print("No orchestrator state found.")
        return

    session_records = state.get("sessions", [])
    if not session_records:
        print("No sessions recorded yet.")
        return

    # Collect best results from session records
    results = []
    for s in session_records:
        sharpe = s.get("best_sharpe")
        dsr = s.get("best_dsr")
        if sharpe is not None:
            results.append(
                {
                    "session": s.get("session_number", "?"),
                    "sharpe": sharpe,
                    "dsr": dsr,
                    "duration": s.get("duration_minutes", 0),
                    "cost": s.get("estimated_cost_usd", 0),
                }
            )

    results.sort(key=lambda x: x.get("sharpe", 0) or 0, reverse=True)

    print(f"{'Session':>8} {'Sharpe':>8} {'DSR':>8} {'Duration':>10} {'Cost':>8}")
    print(f"{'-' * 8:>8} {'-' * 8:>8} {'-' * 8:>8} {'-' * 10:>10} {'-' * 8:>8}")
    for r in results[:20]:
        sharpe = f"{r['sharpe']:.3f}" if r["sharpe"] is not None else "N/A"
        dsr = f"{r['dsr']:.3f}" if r.get("dsr") is not None else "N/A"
        print(f"{r['session']:>8} {sharpe:>8} {dsr:>8} {r['duration']:>9.0f}m ${r['cost']:>7.2f}")


def cmd_orch_respond(args):
    """Respond to a gate request and resume the orchestrator."""
    state = _load_orch_state()
    if not state:
        print("No orchestrator state found.")
        return

    if state.get("status") != "gate_triggered":
        print(f"Orchestrator is not at a gate (status: {state.get('status')})")
        return

    gate_response_path = PROJECT_ROOT / "GATE_RESPONSE.md"
    gate_response_path.write_text(args.message)

    state["status"] = "running"
    state["gate_message"] = None
    name = state.get("name", "unknown")
    filepath = STATE_DIR / f"orchestrator_{name}.json"
    with open(filepath, "w") as f:
        json.dump(state, f, indent=2)

    print("Response written. Orchestrator status set to 'running'.")
    print("Restart the service to resume: systemctl --user start sparky-research")


def main():
    parser = argparse.ArgumentParser(
        prog="sparky",
        description="Sparky AI operator CLI",
    )
    sub = parser.add_subparsers(dest="command")

    sub.add_parser("status", help="Workflow status dashboard")
    sub.add_parser("logs", help="Tail latest session log")
    sub.add_parser("watch", help="Auto-refresh status")
    sub.add_parser("pause", help="Pause workflow")
    sub.add_parser("resume", help="Resume workflow")
    sub.add_parser("stop", help="Stop systemd service")
    sub.add_parser("start", help="Start systemd service")

    p_skip = sub.add_parser("skip", help="Skip a step")
    p_skip.add_argument("step", help="Step name to skip")

    p_retry = sub.add_parser("retry", help="Reset a step for retry")
    p_retry.add_argument("step", help="Step name to retry")

    p_inject = sub.add_parser("inject", help="Inject guidance")
    p_inject.add_argument("message", help="Message to inject")

    sub.add_parser("budget", help="Budget and cost breakdown")
    sub.add_parser("history", help="Step completion timeline")

    # Orchestrator subcommands
    p_orch = sub.add_parser("orch", help="Orchestrator commands")
    orch_sub = p_orch.add_subparsers(dest="orch_command")
    orch_sub.add_parser("status", help="Orchestrator status dashboard")
    orch_sub.add_parser("results", help="Show top results")
    p_orch_respond = orch_sub.add_parser("respond", help="Respond to gate request")
    p_orch_respond.add_argument("message", help="Response message")

    args = parser.parse_args()

    commands = {
        "status": cmd_status,
        "logs": cmd_logs,
        "watch": cmd_watch,
        "pause": cmd_pause,
        "resume": cmd_resume,
        "stop": cmd_stop,
        "start": cmd_start,
        "skip": cmd_skip,
        "retry": cmd_retry,
        "inject": cmd_inject,
        "budget": cmd_budget,
        "history": cmd_history,
    }

    if args.command == "orch":
        orch_commands = {
            "status": cmd_orch_status,
            "results": cmd_orch_results,
            "respond": cmd_orch_respond,
        }
        if args.orch_command in orch_commands:
            orch_commands[args.orch_command](args)
        else:
            p_orch.print_help()
    elif args.command in commands:
        commands[args.command](args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
