#!/home/akamath/sparky-ai/.venv/bin/python3
"""Sparky AI operator CLI.

Usage:
    sparky status    — Dashboard: step, budget, wandb, GPU, alerts
    sparky logs      — Tail latest session log
    sparky watch     — Auto-refresh status every 30s
    sparky pause     — Pause workflow (graceful, after current session)
    sparky resume    — Resume workflow + start systemd service
    sparky stop      — Stop systemd service immediately
    sparky start     — Start systemd service
    sparky skip <step>  — Skip a step
    sparky retry <step> — Reset a step for retry
    sparky inject "msg" — Inject guidance into next session
    sparky budget    — Detailed budget/cost breakdown
    sparky history   — Step completion timeline
    sparky orch all      — Table view of all orchestrators
    sparky orch status [--name N] — Orchestrator status dashboard
    sparky orch results [--name N] — Show top results from wandb
    sparky orch respond [--name N] "msg" — Respond to a gate request and resume
"""

import argparse
import json
import os
import subprocess
import time
from datetime import datetime, timezone
from pathlib import Path

PROJECT_ROOT = Path("/home/akamath/sparky-ai")
STATE_DIR = PROJECT_ROOT / "workflows" / "state"
LOG_DIR = PROJECT_ROOT / "logs" / "research_sessions"
TELEMETRY_DIR = PROJECT_ROOT / "logs" / "telemetry"
ALERTS_LOG = PROJECT_ROOT / "logs" / "alerts.log"
SERVICE_NAME = "sparky-research"


def _load_state() -> dict | None:
    """Load the most recent workflow state file."""
    if not STATE_DIR.exists():
        return None
    state_files = sorted(STATE_DIR.glob("*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    for sf in state_files:
        try:
            with open(sf) as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError):
            continue
    return None


def _save_state(state: dict) -> None:
    """Save workflow state back to disk."""
    name = state.get("workflow_name", "unknown")
    filepath = STATE_DIR / f"{name}.json"
    state["updated_at"] = datetime.now(timezone.utc).isoformat()
    with open(filepath, "w") as f:
        json.dump(state, f, indent=2)


def _get_systemd_status() -> str:
    """Get systemd service status."""
    try:
        result = subprocess.run(
            ["systemctl", "--user", "is-active", SERVICE_NAME],
            capture_output=True,
            text=True,
            timeout=5,
        )
        return result.stdout.strip()
    except Exception:
        return "unknown"


def _get_gpu_stats() -> str:
    """Get GPU utilization and memory."""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total", "--format=csv,noheader,nounits"],
            capture_output=True,
            text=True,
            timeout=5,
        )
        parts = result.stdout.strip().split(", ")
        if len(parts) == 3:
            util, mem_used, mem_total = parts
            return f"{util}% util, {float(mem_used) / 1024:.1f}GB/{float(mem_total) / 1024:.0f}GB"
    except Exception:
        pass
    return "unavailable"


_WANDB_CACHE: list[dict] | None = None


def _get_wandb_runs() -> list[dict]:
    """Fetch all wandb runs via a single GraphQL call (~0.5s vs ~35s with SDK)."""
    global _WANDB_CACHE
    if _WANDB_CACHE is not None:
        return _WANDB_CACHE
    try:
        import requests as _req

        # Read API key from netrc (handles multi-line format)
        api_key = None
        netrc_path = Path.home() / ".netrc"
        if netrc_path.exists():
            tokens = netrc_path.read_text().split()
            for i, tok in enumerate(tokens):
                if tok == "machine" and i + 1 < len(tokens) and tokens[i + 1] == "api.wandb.ai":
                    # Find "password" token after this machine entry
                    for j in range(i + 2, min(i + 8, len(tokens))):
                        if tokens[j] == "password" and j + 1 < len(tokens):
                            api_key = tokens[j + 1]
                            break
                    break
        if not api_key:
            _WANDB_CACHE = []
            return []

        query = """
        query Runs($project: String!, $entity: String!, $order: String, $first: Int) {
          project(name: $project, entityName: $entity) {
            runs(order: $order, first: $first) {
              edges {
                node { name tags summaryMetrics }
              }
            }
          }
        }
        """
        resp = _req.post(
            "https://api.wandb.ai/graphql",
            json={
                "query": query,
                "variables": {
                    "project": "sparky-ai",
                    "entity": "datadex_ai",
                    "order": "-created_at",
                    "first": 500,
                },
            },
            headers={"Authorization": f"Bearer {api_key}"},
            timeout=15,
        )
        resp.raise_for_status()
        edges = resp.json()["data"]["project"]["runs"]["edges"]
        runs = []
        for edge in edges:
            node = edge["node"]
            summary = {}
            sm = node.get("summaryMetrics")
            if sm:
                try:
                    summary = json.loads(sm)
                except (json.JSONDecodeError, TypeError):
                    pass
            runs.append({"name": node.get("name", ""), "tags": node.get("tags") or [], "summary": summary})
        _WANDB_CACHE = runs
        return runs
    except Exception:
        _WANDB_CACHE = []
        return []


def _get_wandb_counts(state: dict) -> str:
    """Get wandb run counts by tag."""
    try:
        runs = _get_wandb_runs()
        total = len(runs)
        tags_to_check = ["sweep", "regime", "ensemble", "feature_analysis"]
        counts = {}
        for run in runs:
            run_tags = set(run["tags"])
            for tag in tags_to_check:
                if tag in run_tags:
                    counts[tag] = counts.get(tag, 0) + 1
        parts = ", ".join(f"{k}: {v}" for k, v in counts.items())
        return f"{total} runs ({parts})" if parts else f"{total} runs"
    except Exception as e:
        return f"unavailable ({e})"


def _get_best_sharpe(state: dict) -> str:
    """Get best Sharpe from wandb."""
    try:
        runs = _get_wandb_runs()
        best = None
        for run in runs:
            s = run["summary"]
            val = s.get("sharpe") or s.get("sharpe_ratio") or s.get("best_sharpe")
            if val is not None:
                if best is None or val > best:
                    best = val
        if best is not None:
            return f"Sharpe {best:.3f}"
        return "N/A"
    except Exception:
        return "N/A"


def _get_latest_log_line() -> str:
    """Get the last meaningful line from latest.log."""
    latest = LOG_DIR / "latest.log"
    if not latest.exists():
        return "(no log)"
    try:
        # Read last few lines and find last non-empty one
        result = subprocess.run(
            ["tail", "-5", str(latest)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        lines = [l.strip() for l in result.stdout.strip().split("\n") if l.strip()]
        if lines:
            line = lines[-1]
            return line[:80] + "..." if len(line) > 80 else line
    except Exception:
        pass
    return "(no log)"


def _get_recent_alerts() -> str:
    """Get recent alerts."""
    if not ALERTS_LOG.exists():
        return "none"
    try:
        result = subprocess.run(
            ["tail", "-3", str(ALERTS_LOG)],
            capture_output=True,
            text=True,
            timeout=5,
        )
        lines = [l.strip() for l in result.stdout.strip().split("\n") if l.strip()]
        if lines:
            return "; ".join(lines[-2:])
    except Exception:
        pass
    return "none"


def cmd_status(_args):
    """Print workflow status dashboard."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return

    svc_status = _get_systemd_status()
    wf_name = state.get("workflow_name", "unknown")
    steps = state.get("steps", {})
    budget = state.get("budget", {})
    current_idx = state.get("current_step_index", 0)
    total_steps = len(steps)

    # Find current step info
    step_names = list(steps.keys())
    if current_idx < total_steps:
        current_step = step_names[current_idx]
        step_info = steps[current_step]
        attempts = step_info.get("attempts", 0)
        max_retries = 3  # default
        step_status = step_info.get("status", "pending")

        # Estimate elapsed time for current step
        last_attempt = step_info.get("last_attempt_at", "")
        elapsed_str = ""
        if last_attempt and step_status == "running":
            try:
                start = datetime.fromisoformat(last_attempt)
                elapsed = (datetime.now(timezone.utc) - start).total_seconds() / 60
                elapsed_str = f", {elapsed:.0f} min elapsed"
            except Exception:
                pass

        step_line = (
            f"Step {current_idx + 1}/{total_steps}: {current_step} (attempt {attempts}/{max_retries}{elapsed_str})"
        )
    else:
        step_line = f"All {total_steps} steps completed"

    hours_used = budget.get("hours_used", 0)
    max_hours = budget.get("max_hours", 24)
    pct = (hours_used / max_hours * 100) if max_hours > 0 else 0

    gpu_stats = _get_gpu_stats()
    wandb_counts = _get_wandb_counts(state)
    best = _get_best_sharpe(state)
    last_log = _get_latest_log_line()
    alerts = _get_recent_alerts()

    print(f"Sparky AI \u2014 {wf_name} ({svc_status})")
    print(f"{step_line}")
    print(f"Budget: {hours_used:.1f} / {max_hours:.1f} hours ({pct:.0f}%)")
    print(f"Wandb: {wandb_counts}")
    print(f"Best: {best}")
    print(f"GPU: {gpu_stats}")
    print(f'Last log: "{last_log}"')
    print(f"Alerts: {alerts}")


def cmd_logs(_args):
    """Tail latest session log."""
    latest = LOG_DIR / "latest.log"
    if not latest.exists():
        print("No log file found.")
        return
    os.execvp("tail", ["tail", "-f", str(latest)])


def cmd_watch(_args):
    """Auto-refresh status every 30s."""
    try:
        while True:
            os.system("clear")
            print(f"[{datetime.now(timezone.utc).strftime('%H:%M:%S UTC')}] sparky watch (Ctrl+C to stop)\n")
            cmd_status(_args)
            print()
            # Show last 10 lines of log
            latest = LOG_DIR / "latest.log"
            if latest.exists():
                result = subprocess.run(
                    ["tail", "-10", str(latest)],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )
                print("--- Latest log ---")
                print(result.stdout.strip())
            time.sleep(30)
    except KeyboardInterrupt:
        print("\nStopped.")


def cmd_pause(_args):
    """Pause workflow."""
    STATE_DIR.mkdir(parents=True, exist_ok=True)
    (STATE_DIR / "PAUSE").touch()
    print("Workflow paused. Current session will finish, then workflow stops.")
    print("Resume with: sparky resume")


def cmd_resume(_args):
    """Resume workflow."""
    pause_file = STATE_DIR / "PAUSE"
    if pause_file.exists():
        pause_file.unlink()
        print("PAUSE file removed.")
    subprocess.run(["systemctl", "--user", "start", SERVICE_NAME])
    print(f"Started {SERVICE_NAME}.")


def cmd_stop(_args):
    """Stop systemd service."""
    subprocess.run(["systemctl", "--user", "stop", SERVICE_NAME])
    print(f"Stopped {SERVICE_NAME}.")


def cmd_start(_args):
    """Start systemd service."""
    subprocess.run(["systemctl", "--user", "start", SERVICE_NAME])
    print(f"Started {SERVICE_NAME}.")


def cmd_skip(args):
    """Skip a workflow step."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return
    step_name = args.step
    steps = state.get("steps", {})
    if step_name not in steps:
        print(f"Step '{step_name}' not found. Available: {', '.join(steps.keys())}")
        return
    steps[step_name]["status"] = "skipped"
    # Advance current_step_index if needed
    step_names = list(steps.keys())
    current_idx = state.get("current_step_index", 0)
    if current_idx < len(step_names) and step_names[current_idx] == step_name:
        state["current_step_index"] = current_idx + 1
    _save_state(state)
    print(f"Step '{step_name}' marked as skipped.")


def cmd_retry(args):
    """Reset a step for retry."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return
    step_name = args.step
    steps = state.get("steps", {})
    if step_name not in steps:
        print(f"Step '{step_name}' not found. Available: {', '.join(steps.keys())}")
        return
    steps[step_name]["attempts"] = 0
    steps[step_name]["status"] = "pending"
    _save_state(state)
    print(f"Step '{step_name}' reset for retry (attempts=0, status=pending).")


def cmd_inject(args):
    """Inject guidance into next session."""
    STATE_DIR.mkdir(parents=True, exist_ok=True)
    inject_file = STATE_DIR / "inject.md"
    inject_file.write_text(args.message)
    print(f"Guidance written to {inject_file}")
    print("Will be injected into the next Claude session prompt, then deleted.")


def cmd_budget(_args):
    """Show detailed budget and cost breakdown."""
    state = _load_state()
    budget = state.get("budget", {}) if state else {}
    hours_used = budget.get("hours_used", 0)
    max_hours = budget.get("max_hours", 24)
    cost = budget.get("estimated_cost_usd", 0)
    runs = budget.get("runs_completed", 0)

    print(f"Budget: {hours_used:.2f} / {max_hours:.1f} hours ({hours_used / max_hours * 100:.1f}%)")
    print(f"Estimated cost: ${cost:.2f}")
    print(f"Total runs: {runs}")

    # Load telemetry files for per-step breakdown
    if TELEMETRY_DIR.exists():
        by_step: dict[str, dict] = {}
        for tf in sorted(TELEMETRY_DIR.glob("*.json")):
            try:
                with open(tf) as f:
                    t = json.load(f)
                step = t.get("step", "unknown")
                if step not in by_step:
                    by_step[step] = {"runs": 0, "hours": 0.0, "cost": 0.0}
                by_step[step]["runs"] += 1
                by_step[step]["hours"] += t.get("duration_minutes", 0) / 60.0
                by_step[step]["cost"] += t.get("estimated_cost_usd", 0)
            except (json.JSONDecodeError, OSError):
                continue

        if by_step:
            print("\nPer-step breakdown:")
            print(f"  {'Step':<30} {'Runs':>5} {'Hours':>8} {'Cost':>8}")
            print(f"  {'-' * 30} {'-' * 5} {'-' * 8} {'-' * 8}")
            for step, info in by_step.items():
                print(f"  {step:<30} {info['runs']:>5} {info['hours']:>8.2f} ${info['cost']:>7.2f}")


def cmd_history(_args):
    """Show step completion timeline."""
    state = _load_state()
    if not state:
        print("No workflow state found.")
        return

    steps = state.get("steps", {})
    print(f"Workflow: {state.get('workflow_name', 'unknown')}")
    print(f"Created: {state.get('created_at', 'unknown')}")
    print()
    print(f"  {'Step':<30} {'Status':<12} {'Attempts':>8} {'Completed':>24}")
    print(f"  {'-' * 30} {'-' * 12} {'-' * 8} {'-' * 24}")
    for name, info in steps.items():
        completed = info.get("completed_at", "") or "-"
        print(f"  {name:<30} {info.get('status', '?'):<12} {info.get('attempts', 0):>8} {completed:>24}")


def _load_orch_state(name: str | None = None) -> dict | None:
    """Load orchestrator state by name, or most recent if name is None."""
    if not STATE_DIR.exists():
        return _reconstruct_orch_state_from_wandb() if name is None else None

    if name:
        filepath = STATE_DIR / f"orchestrator_{name}.json"
        if filepath.exists():
            try:
                with open(filepath) as f:
                    return json.load(f)
            except (json.JSONDecodeError, OSError):
                pass
        return None

    state_files = sorted(STATE_DIR.glob("orchestrator_*.json"), key=lambda p: p.stat().st_mtime, reverse=True)
    for sf in state_files:
        try:
            with open(sf) as f:
                return json.load(f)
        except (json.JSONDecodeError, OSError):
            continue

    return _reconstruct_orch_state_from_wandb()


def _load_all_orch_states() -> list[dict]:
    """Load all orchestrator state files."""
    states = []
    if not STATE_DIR.exists():
        return states
    for sf in sorted(STATE_DIR.glob("orchestrator_*.json"), key=lambda p: p.stat().st_mtime, reverse=True):
        try:
            with open(sf) as f:
                states.append(json.load(f))
        except (json.JSONDecodeError, OSError):
            continue
    return states


def _reconstruct_orch_state_from_wandb() -> dict | None:
    """Reconstruct orchestrator state from wandb runs (read-only, does not save)."""
    try:
        # Find the active directive to get tags
        directives_dir = PROJECT_ROOT / "directives"
        active_link = directives_dir / "active.yaml"
        if not active_link.exists():
            return None

        import yaml

        with open(active_link) as f:
            directive_data = yaml.safe_load(f)

        name = directive_data.get("name", "")
        tags = directive_data.get("wandb_tags", [])
        if not name:
            return None

        from sparky.workflow.orchestrator import OrchestratorState

        state = OrchestratorState.reconstruct_from_wandb(name, tags)
        if state is None:
            return None

        # Read-only: return dict for display without saving to disk.
        # Budget/cost data is not available in wandb, so this is a partial view.
        return state.to_dict()
    except Exception:
        return None


def _get_service_orch_map() -> dict[str, str]:
    """Map orch name -> systemd service name by parsing ExecStart directives."""
    import yaml as _yaml

    result = {}
    svc_dir = Path.home() / ".config" / "systemd" / "user"
    if not svc_dir.exists():
        return result
    for svc_file in svc_dir.glob("sparky-*.service"):
        try:
            text = svc_file.read_text()
            for line in text.splitlines():
                line = line.strip()
                if line.startswith("ExecStart=") and "directives/" in line:
                    yaml_path = PROJECT_ROOT / "directives" / line.split("directives/", 1)[1]
                    if yaml_path.exists():
                        with open(yaml_path) as f:
                            d = _yaml.safe_load(f)
                        if d and "name" in d:
                            result[d["name"]] = svc_file.stem
        except Exception:
            continue
    return result


def _get_service_uptime_minutes(service_name: str) -> float | None:
    """Parse ActiveEnterTimestampMonotonic from systemctl show for elapsed time."""
    try:
        r = subprocess.run(
            ["systemctl", "--user", "show", service_name, "--property=ActiveEnterTimestampMonotonic,ActiveState"],
            capture_output=True,
            text=True,
            timeout=5,
        )
        props = dict(line.split("=", 1) for line in r.stdout.strip().splitlines() if "=" in line)
        if props.get("ActiveState") != "active":
            return None
        # Monotonic timestamp in microseconds
        mono_us = int(props.get("ActiveEnterTimestampMonotonic", "0"))
        if mono_us == 0:
            return None
        # Get current monotonic time from /proc/uptime (seconds since boot)
        with open("/proc/uptime") as f:
            boot_secs = float(f.read().split()[0])
        now_us = int(boot_secs * 1_000_000)
        elapsed_minutes = (now_us - mono_us) / 60_000_000
        return elapsed_minutes if elapsed_minutes > 0 else None
    except Exception:
        return None


def _get_directive_tags() -> dict[str, list[str]]:
    """Map orch name -> wandb_tags from directive YAMLs."""
    import yaml as _yaml

    result = {}
    directives_dir = PROJECT_ROOT / "directives"
    if not directives_dir.exists():
        return result
    for yf in directives_dir.glob("*.yaml"):
        if yf.name == "active.yaml":
            continue
        try:
            with open(yf) as f:
                d = _yaml.safe_load(f)
            if d and "name" in d and "wandb_tags" in d:
                result[d["name"]] = d["wandb_tags"]
        except Exception:
            continue
    return result


def _count_wandb_runs_by_tags(all_runs: list[dict], tags: list[str]) -> int:
    """Count runs matching ALL given tags."""
    tag_set = set(tags)
    return sum(1 for r in all_runs if tag_set.issubset(set(r["tags"])))


def _get_run_metrics(all_runs: list[dict], run_id: str) -> dict:
    """Get max_drawdown and annual_return for a specific wandb run by name."""
    for r in all_runs:
        if r.get("name") == run_id:
            s = r["summary"]
            ar = s.get("annual_return")
            if ar is None:
                tr = s.get("total_return")
                n_obs = s.get("n_observations", 0)
                ppy = s.get("periods_per_year", 365)
                if tr is not None and n_obs and ppy:
                    years = n_obs / ppy
                    ar = (1 + tr) ** (1 / years) - 1 if years > 0 else None
            return {"max_drawdown": s.get("max_drawdown"), "annual_return": ar}
    return {}


def _fmt_elapsed(minutes: float) -> str:
    """Format minutes as e.g. '12m' or '2h3m'."""
    if minutes < 60:
        return f"{minutes:.0f}m"
    h = int(minutes // 60)
    m = int(minutes % 60)
    return f"{h}h{m}m"


def cmd_orch_all(args):
    """Show table view of all orchestrators."""
    states = _load_all_orch_states()
    if not states:
        print("No orchestrator states found.")
        return

    show_all = getattr(args, "all", False)
    wandb_runs = _get_wandb_runs()
    svc_map = _get_service_orch_map()
    dir_tags = _get_directive_tags()

    active_states = []
    completed_states = []
    for s in states:
        status = s.get("status", "?")
        if status in ("running", "gate_triggered"):
            active_states.append(s)
        else:
            completed_states.append(s)

    def _render_row(s: dict, show_active: bool = False) -> str:
        name = s.get("name", "?")
        status = s.get("status", "?")
        sessions = s.get("session_count", 0)
        best = s.get("best_result", {})
        cost = s.get("total_cost_usd", 0)

        # Check for invalidated results
        invalidated = best.get("invalidated", False)
        if invalidated or (status == "done" and not best):
            status_s = "done*"
        else:
            status_s = status

        sharpe = best.get("sharpe")
        dsr = best.get("dsr")
        sharpe_s = f"{sharpe:.3f}" if isinstance(sharpe, (int, float)) and not invalidated else "-"
        dsr_s = f"{dsr:.3f}" if isinstance(dsr, (int, float)) and not invalidated else "-"

        # MaxDD and annual return — try state first, then wandb
        max_dd = best.get("max_drawdown")
        ann_ret = best.get("annual_return")
        if max_dd is None and best.get("run_id"):
            rm = _get_run_metrics(wandb_runs, best["run_id"])
            max_dd = rm.get("max_drawdown")
            if ann_ret is None:
                ann_ret = rm.get("annual_return")

        dd_s = f"{max_dd * 100:.1f}%" if isinstance(max_dd, (int, float)) and not invalidated else "-"
        ar_s = f"{ann_ret * 100:.1f}%" if isinstance(ann_ret, (int, float)) and not invalidated else "-"

        # Active session indicator
        active_s = ""
        if show_active and status == "running":
            svc_name = svc_map.get(name)
            sess_num = sessions + 1
            parts = [f"S{sess_num}"]
            if svc_name:
                uptime = _get_service_uptime_minutes(svc_name)
                if uptime is not None:
                    parts.append(_fmt_elapsed(uptime))
            tags = dir_tags.get(name, [])
            if tags:
                n_runs = _count_wandb_runs_by_tags(wandb_runs, tags)
                parts.append(f"{n_runs} runs")
            active_s = " (" + ", ".join(parts[1:]) + ")" if len(parts) > 1 else ""
            active_s = parts[0] + active_s

        return (
            f"{name:<38} {status_s:<12} {sessions:>4} {sharpe_s:>8} {dsr_s:>7} "
            f"{dd_s:>7} {ar_s:>9} ${cost:>6.2f}  {active_s}"
        )

    header = (
        f"{'Name':<38} {'Status':<12} {'Sess':>4} {'Sharpe':>8} {'DSR':>7} "
        f"{'MaxDD':>7} {'Ann.Ret':>9} {'Cost':>7}  {'Active'}"
    )
    sep = "-" * len(header)

    if active_states:
        print(header)
        print(sep)
        for s in active_states:
            print(_render_row(s, show_active=True))
        print()

    if completed_states and not show_all:
        print(f"{len(completed_states)} completed orchestrator(s) hidden (use --all)")
    elif completed_states and show_all:
        if not active_states:
            print(header)
            print(sep)
        else:
            print("Completed:")
        for s in completed_states:
            print(_render_row(s))


def cmd_orch_status(_args):
    """Print orchestrator status dashboard."""
    name = getattr(_args, "name", None)
    state = _load_orch_state(name)
    if not state:
        print("No orchestrator state found.")
        return

    name = state.get("name", "unknown")
    status = state.get("status", "unknown")
    sessions = state.get("session_count", 0)
    best = state.get("best_result", {})
    stall = state.get("stall_counter", 0)
    crash = state.get("crash_counter", 0)
    cost = state.get("total_cost_usd", 0)
    hours = state.get("total_hours", 0)
    gate_msg = state.get("gate_message")

    best_sharpe = best.get("sharpe", "N/A")
    best_dsr = best.get("dsr", "N/A")
    if isinstance(best_sharpe, float):
        best_sharpe = f"{best_sharpe:.3f}"
    if isinstance(best_dsr, float):
        best_dsr = f"{best_dsr:.3f}"

    print(f"Orchestrator: {name} ({status})")
    print(f"Sessions: {sessions}")
    print(f"Best: Sharpe={best_sharpe}, DSR={best_dsr}")
    print(f"Budget: {hours:.1f}h, ${cost:.2f}")
    print(f"Stall counter: {stall}")
    print(f"Crash counter: {crash}")
    if gate_msg:
        print(f"Gate message: {gate_msg}")


def cmd_orch_results(_args):
    """Show top results from wandb for the orchestrator directive."""
    name = getattr(_args, "name", None)
    state = _load_orch_state(name)
    if not state:
        print("No orchestrator state found.")
        return

    session_records = state.get("sessions", [])
    if not session_records:
        print("No sessions recorded yet.")
        return

    # Collect best results from session records
    results = []
    for s in session_records:
        sharpe = s.get("best_sharpe")
        dsr = s.get("best_dsr")
        if sharpe is not None:
            results.append(
                {
                    "session": s.get("session_number", "?"),
                    "sharpe": sharpe,
                    "dsr": dsr,
                    "duration": s.get("duration_minutes", 0),
                    "cost": s.get("estimated_cost_usd", 0),
                }
            )

    results.sort(key=lambda x: x.get("sharpe", 0) or 0, reverse=True)

    print(f"{'Session':>8} {'Sharpe':>8} {'DSR':>8} {'Duration':>10} {'Cost':>8}")
    print(f"{'-' * 8:>8} {'-' * 8:>8} {'-' * 8:>8} {'-' * 10:>10} {'-' * 8:>8}")
    for r in results[:20]:
        sharpe = f"{r['sharpe']:.3f}" if r["sharpe"] is not None else "N/A"
        dsr = f"{r['dsr']:.3f}" if r.get("dsr") is not None else "N/A"
        print(f"{r['session']:>8} {sharpe:>8} {dsr:>8} {r['duration']:>9.0f}m ${r['cost']:>7.2f}")


def cmd_orch_respond(args):
    """Respond to a gate request and resume the orchestrator."""
    name = getattr(args, "name", None)
    state = _load_orch_state(name)
    if not state:
        print("No orchestrator state found.")
        return

    if state.get("status") != "gate_triggered":
        print(f"Orchestrator is not at a gate (status: {state.get('status')})")
        return

    gate_response_path = PROJECT_ROOT / "GATE_RESPONSE.md"
    gate_response_path.write_text(args.message)

    state["status"] = "running"
    state["gate_message"] = None
    name = state.get("name", "unknown")
    filepath = STATE_DIR / f"orchestrator_{name}.json"
    with open(filepath, "w") as f:
        json.dump(state, f, indent=2)

    print("Response written. Orchestrator status set to 'running'.")
    print("Restart the service to resume: systemctl --user start sparky-research")


def main():
    parser = argparse.ArgumentParser(
        prog="sparky",
        description="Sparky AI operator CLI",
    )
    sub = parser.add_subparsers(dest="command")

    sub.add_parser("status", help="Workflow status dashboard")
    sub.add_parser("logs", help="Tail latest session log")
    sub.add_parser("watch", help="Auto-refresh status")
    sub.add_parser("pause", help="Pause workflow")
    sub.add_parser("resume", help="Resume workflow")
    sub.add_parser("stop", help="Stop systemd service")
    sub.add_parser("start", help="Start systemd service")

    p_skip = sub.add_parser("skip", help="Skip a step")
    p_skip.add_argument("step", help="Step name to skip")

    p_retry = sub.add_parser("retry", help="Reset a step for retry")
    p_retry.add_argument("step", help="Step name to retry")

    p_inject = sub.add_parser("inject", help="Inject guidance")
    p_inject.add_argument("message", help="Message to inject")

    sub.add_parser("budget", help="Budget and cost breakdown")
    sub.add_parser("history", help="Step completion timeline")

    # Orchestrator subcommands
    p_orch = sub.add_parser("orch", help="Orchestrator commands")
    orch_sub = p_orch.add_subparsers(dest="orch_command")
    p_orch_all = orch_sub.add_parser("all", help="Table view of all orchestrators")
    p_orch_all.add_argument("--all", action="store_true", help="Show completed orchestrators too")
    p_orch_status = orch_sub.add_parser("status", help="Orchestrator status dashboard")
    p_orch_status.add_argument("--name", help="Orchestrator name (default: most recent)")
    p_orch_results = orch_sub.add_parser("results", help="Show top results")
    p_orch_results.add_argument("--name", help="Orchestrator name (default: most recent)")
    p_orch_respond = orch_sub.add_parser("respond", help="Respond to gate request")
    p_orch_respond.add_argument("--name", help="Orchestrator name (default: most recent)")
    p_orch_respond.add_argument("message", help="Response message")

    args = parser.parse_args()

    commands = {
        "status": cmd_status,
        "logs": cmd_logs,
        "watch": cmd_watch,
        "pause": cmd_pause,
        "resume": cmd_resume,
        "stop": cmd_stop,
        "start": cmd_start,
        "skip": cmd_skip,
        "retry": cmd_retry,
        "inject": cmd_inject,
        "budget": cmd_budget,
        "history": cmd_history,
    }

    if args.command == "orch":
        orch_commands = {
            "all": cmd_orch_all,
            "status": cmd_orch_status,
            "results": cmd_orch_results,
            "respond": cmd_orch_respond,
        }
        if args.orch_command in orch_commands:
            orch_commands[args.orch_command](args)
        else:
            p_orch.print_help()
    elif args.command in commands:
        commands[args.command](args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
