name: p001_validation_eth
objective: |
  Validation of ETH TIER 1 candidates identified during exploration and investigation phases.
  No parameter sweeps. No new signal families. Pure validation of known candidates.

  ## Setup

  Read configs/project_001/candidates.yaml and extract the three ETH candidates:
  - eth_don4h_138_47_flat
  - eth_don4h_164_47_flat
  - eth_don8h_83_33_iv

  For each candidate, build the config dict with these keys:
    {
      "asset": <str>,
      "timeframe": <str>,
      "signal_type": <str>,
      "signal_params": <dict>,
      "sizing": <str>,
      "sizing_params": <dict>   # omit if not present in candidates.yaml
    }

  ## Step 1: Investigation

  ```python
  from analysis_runner import run_full_investigation

  # run_full_investigation(config: dict) -> dict
  # config keys: asset, timeframe, signal_type, signal_params, sizing, sizing_params
  # Returns: trade_profile, edge_attribution, regime_decomposition

  investigation_results = run_full_investigation(config)
  ```

  Produces: trade_profile, edge_attribution, regime_decomposition.

  ## Step 2: Full Validation Battery

  ```python
  from analysis_runner import run_full_validation_battery

  # run_full_validation_battery(config: dict) -> dict
  # Same config dict as run_full_investigation.
  # Runs all 12 validation tests.

  validation_results = run_full_validation_battery(config)
  ```

  Runs all 12 validation tests. Collect pass/fail per test and the summary verdict.

  ## Step 3: Candidate Report

  ```python
  from report_generator import generate_candidate_report

  # generate_candidate_report(
  #   candidate_id: str,
  #   investigation_results: dict,
  #   validation_results: dict,
  #   output_dir: str
  # ) -> str   (returns path to generated HTML report)

  report_path = generate_candidate_report(
      candidate_id,
      investigation_results,
      validation_results,
      output_dir="reports/project_001"
  )
  ```

  ## Step 4: Export Daily Returns

  Export daily returns CSV for each candidate to:
    reports/project_001/portfolio_inputs/{candidate_id}_returns.csv

  The CSV must have columns: date, returns_30bps, returns_50bps.
  These will be consumed by the portfolio construction phase.

  ## Step 5: ETH Summary

  Write a human-readable Markdown summary to:
    reports/project_001/sessions/eth_validation_summary.md

  Include per-candidate: Sharpe (30 bps, 50 bps), DSR, MaxDD, n_trades, win rate,
  sub-period metrics (full IS, 2017+, 2020+), validation battery pass/fail counts,
  and final verdict (PASS / CONDITIONAL / FAIL).

  ## Step 6: Update State

  Update state/core_memory.json with per-candidate verdicts. Structure:
    {
      "eth_validation": {
        "<candidate_id>": {
          "verdict": "PASS" | "CONDITIONAL" | "FAIL",
          "sharpe_30bps": <float>,
          "sharpe_50bps": <float>,
          "dsr": <float>,
          "max_dd": <float>,
          "validation_pass_count": <int>,
          "notes": "<str>"
        }
      }
    }

  ## Step 7: W&B Logging

  Log results to wandb with tags [project_001, validation, eth].

  Use tracker.log_experiment() for each candidate (these are validated results, not sweeps):
  ```python
  from sparky.tracking.experiment import ExperimentTracker
  from sparky.tracking.metrics import compute_all_metrics

  tracker = ExperimentTracker(experiment_name="p001_validation_eth")
  metrics = compute_all_metrics(returns, n_trials=16269)
  tracker.log_experiment(
      candidate_id,
      config=config,
      metrics=metrics,
      tags=["project_001", "validation", "eth"]
  )
  ```

  ## Special Notes

  eth_don4h_138_47_flat — High MaxDD (-38.8%). Investigate whether the drawdown is
  concentrated in a single event (e.g., 2022 bear, LUNA/FTX) or distributed across
  many events. If it is a single concentrated event, document the finding clearly but
  do NOT auto-fail the candidate. Single-event drawdowns are structurally different from
  persistent strategy weakness. Report the finding in the summary and candidate report.

  eth_don4h_164_47_flat — Closely related to eth_don4h_138_47_flat (same exit, longer
  entry). Report whether the longer entry period materially reduces MaxDD vs 138/47.

  eth_don8h_83_33_iv — Best ETH risk-adjusted candidate (MaxDD=-9.5%). This is the
  anchor candidate. Confirm walk-forward stability before declaring it primary.

  ## Loop Structure

  ```python
  import yaml

  with open("configs/project_001/candidates.yaml") as f:
      all_candidates = yaml.safe_load(f)["candidates"]

  eth_ids = ["eth_don4h_138_47_flat", "eth_don4h_164_47_flat", "eth_don8h_83_33_iv"]

  for candidate_id in eth_ids:
      raw = all_candidates[candidate_id]
      config = {
          "asset": raw["asset"],
          "timeframe": raw["timeframe"],
          "signal_type": raw["signal_type"],
          "signal_params": raw["signal_params"],
          "sizing": raw["sizing"],
          "sizing_params": raw.get("sizing_params", {}),
      }
      investigation_results = run_full_investigation(config)
      validation_results = run_full_validation_battery(config)
      report_path = generate_candidate_report(
          candidate_id, investigation_results, validation_results,
          output_dir="reports/project_001"
      )
      # ... export returns, update state, log to wandb
  ```

constraints:
  assets: [eth]
  timeframes: [4h, 8h]
  gpu_required: false
  transaction_costs_bps: 30
  n_trials_start: 16269
  n_trials_cumulative: true

strategy_space: []

stopping_criteria:
  stop_on_success: false
  success:
    min_sharpe: 1.0
    min_dsr: 0.95
  budget:
    max_sessions: 3
    max_hours: 2
    max_cost_usd: 15
    digest_every: 1
  stall:
    sessions_without_improvement: 3
    improvement_threshold: 0.01
    diversity_threshold: 0.99

session_limits:
  max_session_minutes: 60
  max_cost_per_session: 8.0
  min_session_minutes: 3
  max_consecutive_crashes: 3

wandb_tags: [project_001, validation, eth]

gates:
  - trigger: stall_detected
    action: pause_and_alert

exclusions:
  - "No parameter sweeps. This is validation of KNOWN candidates only."
  - "Use analysis_runner functions exclusively — do NOT write standalone backtest scripts."
  - "Do NOT proceed to OOS evaluation. Stay in-sample."
  - "Do not build paper trading infrastructure."
  - "Always use sparky.data.loader.load() — never pd.read_parquet()"
  - "Always use compute_all_metrics and report DSR"
  - "Report Sharpe at BOTH 30 bps and 50 bps"
  - "n_trials=16269 (cumulative across all exploration). Use this for DSR calculations."
  - "Do NOT touch git"
  - "periods_per_year: 2190 (4h), 1095 (8h). Never use 252 or 365 for intraday."
  - "Do NOT overwrite existing reports. Before writing any file in reports/, check if it already exists. If it does, skip or append with a session-numbered suffix (e.g., _session002.md)."
